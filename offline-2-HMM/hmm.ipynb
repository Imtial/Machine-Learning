{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d2fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm as gaussian\n",
    "from scipy import linalg\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3816614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sample input and output for HMM/Input/data.txt') as f:\n",
    "    rainfall = np.loadtxt(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35396f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sample input and output for HMM/Input/parameters.txt') as f:\n",
    "    nstates = int(next(f))\n",
    "    trans_mat = np.asarray([[float(x) for x in next(f).strip().split('\\t')] for i in range(nstates)])\n",
    "    mu = np.asarray([float(x) for x in next(f).strip().split('\\t')])\n",
    "    sigma = np.asarray([float(x) for x in next(f).strip().split('\\t')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3037c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mat = np.asarray([[gaussian.pdf(x, loc=mu[i], scale=math.sqrt(sigma[i])) for x in rainfall] for i in range(nstates)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef020ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs, states, init_prob, trans_mat, emit_mat):\n",
    "    prev_prob = np.log(init_prob * emit_mat[0]).reshape(1, -1)\n",
    "    prev_st = np.full((1, states), -1)\n",
    "    \n",
    "    for ep in emit_mat[1:]:\n",
    "        probs = prev_prob[-1].reshape(-1, 1) + np.log(trans_mat * ep)\n",
    "        prev_prob = np.concatenate((prev_prob, probs.max(axis=0).reshape(1, -1)))\n",
    "        prev_st = np.concatenate((prev_st, probs.argmax(axis=0).reshape(1, -1)))\n",
    "    \n",
    "    most_likely_st = np.array([prev_prob[-1].argmax()])\n",
    "    for st in prev_st[:0:-1]:\n",
    "        most_likely_st = np.append(most_likely_st, st[most_likely_st[-1]])\n",
    "    \n",
    "    st, counts = np.unique(most_likely_st, return_counts=True)\n",
    "    \n",
    "    return most_likely_st, dict((st[i], counts[i]) for i in range(states))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebe08ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_prob:  [0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "init_prob = np.full(nstates, 1/nstates)\n",
    "print('init_prob: ', init_prob)\n",
    "most_likely_states, state_counts = viterbi(rainfall, nstates, init_prob, trans_mat, emit_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e25abb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad4c532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 291, 1: 709}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs, init_prob, trans_mat, emit_mat):\n",
    "    T = obs.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((T, m))\n",
    "    alpha[0] = init_prob * emit_mat[0]\n",
    "    alpha[0] /= np.sum(alpha[0])\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        for i in range(m):\n",
    "            alpha[t, i] = alpha[t - 1].dot(trans_mat[:, i] * emit_mat[t, i])\n",
    "        alpha[t] /= np.sum(alpha[t])\n",
    "            \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(obs, trans_mat, emit_mat):\n",
    "    T = obs.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    beta = np.zeros((T, m))\n",
    "    beta[-1] = np.ones(m)\n",
    "    beta[-1] /= np.sum(beta[-1])\n",
    "    \n",
    "    for t in range(T-2, -1, -1):\n",
    "        for i in range(m):\n",
    "            beta[t, i] = trans_mat[i].dot(beta[t+1] * emit_mat[t+1])\n",
    "        beta[t] /= np.sum(beta[t])\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(obs, init_prob, trans_mat, emit_mat, n_iter):\n",
    "    T = obs.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    updated_trans_mat = trans_mat.copy()\n",
    "    updated_emit_mat = emit_mat.copy()\n",
    "    \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(obs, init_prob, updated_trans_mat, updated_emit_mat)\n",
    "        beta = backward(obs, updated_trans_mat, updated_emit_mat)\n",
    "        \n",
    "        xi = np.zeros((m, m, T-1))\n",
    "        for t in range(T-1):\n",
    "            denom = (alpha[t].dot(updated_trans_mat) * updated_emit_mat[t+1]).dot(beta[t+1])\n",
    "            for i in range(m):\n",
    "                numer = alpha[t, i] * updated_trans_mat[i] * updated_emit_mat[t+1] * beta[t+1]\n",
    "                xi[i, :, t] = numer / denom\n",
    "        \n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        updated_trans_mat = np.sum(xi, axis=2) / np.sum(gamma, axis=1).reshape(-1, 1)\n",
    "        \n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T-2], axis=0).reshape(-1, 1)))\n",
    "        \n",
    "        denom = np.sum(gamma, axis=1)\n",
    "        updated_emit_mat /= denom\n",
    "    \n",
    "    return updated_trans_mat, updated_emit_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat_trained, emit_mat_trained = baum_welch(rainfall, init_prob, trans_mat, emit_mat, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1710c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3604785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(init_prob, trans_mat, emit_mat, norm):\n",
    "    T = emit_mat.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((T, m))\n",
    "    alpha[0] = init_prob * emit_mat[0]\n",
    "    norm[0] = 1. / np.sum(alpha[0])\n",
    "    alpha[0] *= norm[0]\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        for i in range(m):\n",
    "            alpha[t, i] = alpha[t - 1].dot(trans_mat[:, i] * emit_mat[t, i])\n",
    "        norm[t] = 1. / np.sum(alpha[t])\n",
    "        alpha[t] *= norm[t]\n",
    "            \n",
    "    return alpha\n",
    "\n",
    "# def forward_t(init_prob, trans_mat, emit_mat, norm):\n",
    "#     T = emit_mat.shape[0]\n",
    "#     m = trans_mat.shape[0]\n",
    "    \n",
    "#     alpha = np.zeros((T, m))\n",
    "#     alpha[0] = init_prob * emit_mat[0]\n",
    "#     norm[0] = 1. / np.sum(alpha[0])\n",
    "#     alpha[0] *= norm[0]\n",
    "    \n",
    "#     for t in range(1, T):\n",
    "#         for i in range(m):\n",
    "#             for j in range(m):\n",
    "#                 temp = alpha[t-1, j] * trans_mat[j, i] * emit_mat[t, i]\n",
    "#                 alpha[t, i] += temp\n",
    "#         norm[t] = 1. / np.sum(alpha[t])\n",
    "#         alpha[t] *= norm[t]\n",
    "            \n",
    "#     return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0af285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(trans_mat, emit_mat, norm):\n",
    "    T = emit_mat.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    beta = np.zeros((T, m))\n",
    "    beta[-1] = np.ones(m)\n",
    "    \n",
    "    for t in range(T-2, -1, -1):\n",
    "        for i in range(m):\n",
    "            beta[t, i] = trans_mat[i].dot(beta[t+1] * emit_mat[t+1])\n",
    "        beta[t] *= norm[t]\n",
    "    \n",
    "    return beta\n",
    "\n",
    "# def backward_t(trans_mat, emit_mat, norm):\n",
    "#     T = emit_mat.shape[0]\n",
    "#     m = trans_mat.shape[0]\n",
    "#     beta = np.zeros((T, m))\n",
    "    \n",
    "#     beta[-1] = np.ones(m)\n",
    "    \n",
    "#     for t in range(T-2, -1, -1):\n",
    "#         for i in range(m):\n",
    "#             for j in range(m):\n",
    "#                 temp = beta[t+1, j] * trans_mat[i, j] * emit_mat[t+1, j]\n",
    "#                 beta[t, i] += temp\n",
    "#             beta[t, i] *= norm[t]\n",
    "#     return beta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53cbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(obs, init_prob, trans_mat, emit_mat, n_iter):\n",
    "    T = emit_mat.shape[0]\n",
    "    m = trans_mat.shape[0]\n",
    "    \n",
    "    updated_trans_mat = trans_mat.copy()\n",
    "    updated_emit_mat = emit_mat.copy()\n",
    "    \n",
    "    norm = np.zeros(T)\n",
    "    \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(init_prob, updated_trans_mat, updated_emit_mat, norm)\n",
    "        beta = backward(updated_trans_mat, updated_emit_mat, norm)\n",
    "\n",
    "        alphaXbeta = alpha * beta / norm.reshape(-1, 1)\n",
    "        denoms = alphaXbeta.sum(axis=0)\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                numer = 0\n",
    "                for t in range(T-1):\n",
    "                    numer += alpha[t, i] * updated_trans_mat[i, j] * beta[t+1, j] * updated_emit_mat[t+1, j]\n",
    "                updated_trans_mat[i, j] = numer / denoms[i]\n",
    "                \n",
    "        alphaXbeta *= norm.reshape(-1, 1)\n",
    "        alphaXbeta /= alphaXbeta.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "        tmp = alphaXbeta * obs.reshape(-1, 1)\n",
    "        _mu_ = tmp.sum(axis=0) / alphaXbeta.sum(axis=0)\n",
    "\n",
    "        diff = obs.reshape(-1, 1) - _mu_\n",
    "        _sigma_ = (alphaXbeta * (diff ** 2)).sum(axis=0) / alphaXbeta.sum(axis=0)\n",
    "\n",
    "        updated_emit_mat = np.asarray([[gaussian.pdf(x, loc=_mu_[i], scale=math.sqrt(_sigma_[i])) for x in obs] for i in range(m)]).T\n",
    "        \n",
    "    return updated_trans_mat, _mu_, _sigma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f584ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_mat_trained, mu_trained, sigma_trained = baum_welch(rainfall, init_prob, trans_mat, emit_mat, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abc5aa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82795699, 0.17204301],\n",
       "       [0.21719457, 0.78054299]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_mat_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f8585ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([150.1898689 , 100.20940296])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd1780b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.031877  , 8.71346514])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89bc1103",
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_mat_trained = np.asarray([[gaussian.pdf(x, loc=mu_trained[i], scale=math.sqrt(sigma_trained[i])) for x in rainfall] for i in range(nstates)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0634ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_states_after_train, state_counts_after_train = viterbi(rainfall, nstates, init_prob, trans_mat_trained, emit_mat_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f599af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 558, 1: 442}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_counts_after_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9cecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('viterbi_wo_learning.txt', 'w') as f:\n",
    "    emit_mat = np.asarray([[gaussian.pdf(x, loc=mu[i], scale=math.sqrt(sigma[i])) for x in rainfall] for i in range(nstates)]).T\n",
    "    init_prob = np.full(nstates, 1/nstates)\n",
    "    most_likely_states, state_counts = viterbi(rainfall, nstates, init_prob, trans_mat, emit_mat)\n",
    "    most_likely_states = ['El Nino' if x == 0 else 'La Nina' for x in most_likely_states]\n",
    "    f.write('\\n'.join(most_likely_states))\n",
    "    print(state_counts)\n",
    "    \n",
    "with open('parameters_learned.txt', 'w') as f:\n",
    "    trans_mat_trained, mu_trained, sigma_trained = baum_welch(rainfall, init_prob, trans_mat, emit_mat, n_iter=20)\n",
    "    f.write(str(nstates)+'\\n')\n",
    "    \n",
    "    [f.write('\\t'.join([str(v) for v in row])+'\\n') for row in trans_mat_trained]\n",
    "    f.write('\\t'.join([str(mu_x) for mu_x in mu_trained]) + '\\n')\n",
    "    f.write('\\t'.join([str(sigma_x) for sigma_x in sigma_trained]))\n",
    "    \n",
    "with open('viterbi_after_learning.txt', 'w') as f:\n",
    "    emit_mat_trained = np.asarray([[gaussian.pdf(x, loc=mu_trained[i], scale=math.sqrt(sigma_trained[i])) for x in rainfall] for i in range(nstates)]).T\n",
    "    most_likely_states_after_train, state_counts_after_train = viterbi(rainfall, nstates, init_prob, trans_mat_trained, emit_mat_trained)\n",
    "    most_likely_states_after_train = ['El Nino' if x == 0 else 'La Nina' for x in most_likely_states_after_train]\n",
    "    f.write('\\n'.join(most_likely_states_after_train))\n",
    "    print(state_counts_after_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9818ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "['\\t'.join([str(mu_x) for mu_x in mu_trained]), '\\t'.join([str(sigma_x) for sigma_x in sigma_trained])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b3d858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_dist(trans_mat):\n",
    "    w, vl = linalg.eig(trans_mat, left=True, right=False)\n",
    "    vec = vl[:, np.isclose(w, 1)][:, 0]\n",
    "    return vec / vec.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afeab296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(w, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b22f2117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31622777],\n",
       "       [-0.9486833 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl[:, np.isclose(w, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "941fd01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(vl[:, np.isclose(w, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a043c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_prob(transition_matrix):\n",
    "    lam, vec = linalg.eig(transition_matrix, left=True, right=False)\n",
    "    # print(lam, vec)\n",
    "    evec1 = vec[:,np.isclose(lam, 1)]\n",
    "    evec1 = evec1[:,0]\n",
    "    # print(evec1)\n",
    "    pi = evec1/evec1.sum()\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99293b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.75])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_prob(trans_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d44e8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.75])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_dist(trans_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16a1e557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.31622777],\n",
       "       [ 0.70710678, -0.9486833 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc120c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
